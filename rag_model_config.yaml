databricks_resources:
  llm_endpoint_name: databricks-meta-llama-3-1-70b-instruct
  vector_search_endpoint_name: call_transcripts_vector_endpoint
  source_delta_table: dev.call_analytics.transcripts
  embedding_model_endpoint_name: e5-small-v2
  mlflow_run_name: call_transcript_rag
  artifact_path: call_transcript_artifacts
  model_name_full: dev.call_analytics.transcript_model

input_example:
  messages:
    - content: What is the most common complaint about T-Mobile service?
      role: user

llm_config:
  llm_parameters:
    max_tokens: 1500
    temperature: 0.01
  llm_prompt_template: |
    Answer questions based only on the provided information. 
    If you do not know the answer to a question, say you do not know the answer. 
    Here is the history of the current conversation: {chat_history}. 
    And here is some context which may or may not help you answer the following question: {context}.  
    Answer directly, do not repeat the question, do not mention the context or the question. 
    Based on this context, answer this question: {question}
  llm_prompt_template_variables:
    - context
    - chat_history
    - question

retriever_config:
  chunk_template: "Passage: {chunk_text}\n"
  data_pipeline_tag: call_transcript_RAG
  parameters:
    k: 2
  schema:
    chunk_text: call_transcript
    primary_key: id
  vector_search_index: "dev.call_analytics.transcripts_index"
